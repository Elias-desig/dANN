{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63259637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from masks import rf_mask, somatic_mask\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "img_size = 28\n",
    "num_somas = 64\n",
    "num_dendrites = img_size ** 2\n",
    "connectivity = math.ceil(num_dendrites / num_somas)\n",
    "print(connectivity)\n",
    "d_local_mask = rf_mask([img_size,img_size], num_dendrites, num_somas,type='local', rf_size=16)\n",
    "d_random_mask = rf_mask([img_size,img_size], num_dendrites, num_somas,type='random', rf_size=16)\n",
    "d_global_mask = rf_mask([img_size,img_size], num_dendrites, num_somas,type='global', rf_size=16)\n",
    "single_rf = d_local_mask[0].view(28,28)\n",
    "s_mask = somatic_mask(200, 100)\n",
    "plt.imshow(single_rf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0fb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "global_rf = torch.sum(d_global_mask[13:26].view(-1,28,28), dim=0)\n",
    "s_mask = somatic_mask(num_dendrites, num_somas)\n",
    "plt.imshow(global_rf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8357824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "summed = torch.sum(d_local_mask.view(-1, 28, 28), dim=0)\n",
    "summed /= torch.max(summed)\n",
    "plt.imshow(summed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb70dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import dANN, vANN, count_parameters\n",
    "from train import train, test\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "\n",
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # Converts to [0,1] range\n",
    "    v2.Normalize(mean=[0.1307], std=[0.3081])  # MNIST-specific normalization\n",
    "])\n",
    "\n",
    "\n",
    "os.makedirs('./data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843713ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "209514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:34<00:00, 109.95it/s]\n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 151.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.7225063505172729, test loss: 1.6521585905075074, test accuracy: 0.8078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:32<00:00, 114.23it/s]\n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 151.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6507577699661256, test loss: 1.6272512691497802, test accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 458/3750 [00:04<00:29, 112.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 36\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     test_loss, accuracy \u001b[38;5;241m=\u001b[39m test(model, test_loader, device)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dANN/train.py:21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)    \n\u001b[0;32m---> 21\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update the model parameters\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mapply_masks()\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/optim/adam.py:220\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    214\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m            and returns the loss.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/optim/optimizer.py:426\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mis_compiling()\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_built()\n\u001b[0;32m--> 426\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m     ):\n\u001b[1;32m    428\u001b[0m         capturing \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_current_stream_capturing()\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    431\u001b[0m             group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups\n\u001b[1;32m    432\u001b[0m         ):\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/cuda/__init__.py:165\u001b[0m, in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_compiled():\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_nvml_based_avail\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# The user has set an env variable to request this availability check that attempts to avoid fork poisoning by\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# using NVML at the cost of a weaker CUDA availability assessment. Note that if NVML discovery/initialization\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# fails, this assessment falls back to the default CUDA Runtime API assessment (`cudaGetDeviceCount`)\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m device_count() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# The default availability inspection never throws and returns 0 if the driver is missing or can't\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# be initialized. This uses the CUDA Runtime API `cudaGetDeviceCount` which in turn initializes the CUDA Driver\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# API via `cuInit`\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/cuda/__init__.py:158\u001b[0m, in \u001b[0;36m_nvml_based_avail\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_nvml_based_avail\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPYTORCH_NVML_BASED_CUDA_CHECK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m<frozen os>:783\u001b[0m, in \u001b[0;36mgetenv\u001b[0;34m(key, default)\u001b[0m\n",
      "File \u001b[0;32m<frozen _collections_abc>:807\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, key, default)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:682\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:765\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(value)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=128, shuffle=False)\n",
    "\n",
    "sample = mnist_train[0]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = dANN([28,28], 256,32,10, 'local').to(device)\n",
    "print(count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    test_loss, accuracy = test(model, test_loader, device)\n",
    "    print(f'train loss: {train_loss}, test loss: {test_loss}, test accuracy: {accuracy}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c41dabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "cpu\n",
      "1066740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:02<00:00, 27.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0156344885129664, test loss: 0.5623702093770232, test accuracy: 0.7966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:20<00:00, 22.77it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:02<00:00, 29.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4924597360177843, test loss: 0.4765417685237112, test accuracy: 0.8261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:23<00:00, 19.70it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 23.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.43252164141328603, test loss: 0.44022689929491354, test accuracy: 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.18it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.40251569014622457, test loss: 0.4254935242329972, test accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 16.84it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3826760805682587, test loss: 0.40882786882074573, test accuracy: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.20it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.36787741861617895, test loss: 0.3924261671078356, test accuracy: 0.8562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.30it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.35470034134413386, test loss: 0.3823119833876815, test accuracy: 0.8631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.18it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 23.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3443335847559768, test loss: 0.3736806383615808, test accuracy: 0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:28<00:00, 16.51it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 25.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.33557420826034506, test loss: 0.36625154240976404, test accuracy: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:24<00:00, 19.21it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 22.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.32656634463938566, test loss: 0.3652019417738613, test accuracy: 0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:24<00:00, 19.20it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 20.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3203743046471305, test loss: 0.3546313818874238, test accuracy: 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:28<00:00, 16.42it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3138698885944098, test loss: 0.3509423398896109, test accuracy: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.37it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.30799802016220623, test loss: 0.34510084986686707, test accuracy: 0.8771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 356/469 [00:21<00:06, 16.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m epochs = \u001b[32m20\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     train_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     test_loss, accuracy = test(model, test_loader, device)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dANN-1/train.py:9\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, optimizer, device, masked)\u001b[39m\n\u001b[32m      6\u001b[39m model.train()\n\u001b[32m      7\u001b[39m loss_total = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/datasets/mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = Image.fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/_container.py:51\u001b[39m, in \u001b[36mCompose.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m     49\u001b[39m needs_unpacking = \u001b[38;5;28mlen\u001b[39m(inputs) > \u001b[32m1\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     outputs = \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     inputs = outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py:69\u001b[39m, in \u001b[36mTransform.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m     63\u001b[39m needs_transform_list = \u001b[38;5;28mself\u001b[39m._needs_transform_list(flat_inputs)\n\u001b[32m     64\u001b[39m params = \u001b[38;5;28mself\u001b[39m.make_params(\n\u001b[32m     65\u001b[39m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[32m     66\u001b[39m )\n\u001b[32m     68\u001b[39m flat_outputs = [\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[32m     71\u001b[39m ]\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:304\u001b[39m, in \u001b[36mToDtype.transform\u001b[39m\u001b[34m(self, inpt, params)\u001b[39m\n\u001b[32m    299\u001b[39m         warnings.warn(\n\u001b[32m    300\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mscale was set to True but no dtype was specified for images or videos: no scaling will be done.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    301\u001b[39m         )\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inpt\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py:49\u001b[39m, in \u001b[36mTransform._call_kernel\u001b[39m\u001b[34m(self, functional, inpt, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m, functional: Callable, inpt: Any, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m     48\u001b[39m     kernel = _get_kernel(functional, \u001b[38;5;28mtype\u001b[39m(inpt), allow_passthrough=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_utils.py:32\u001b[39m, in \u001b[36m_kernel_tv_tensor_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(inpt, *args, **kwargs)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(kernel)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(inpt, *args, **kwargs):\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# If you're wondering whether we could / should get rid of this wrapper,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# lost after the first operation due to our own __torch_function__\u001b[39;00m\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# logic.\u001b[39;00m\n\u001b[32m     31\u001b[39m     output = kernel(inpt.as_subclass(torch.Tensor), *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtv_tensors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlike\u001b[49m\u001b[43m=\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:841\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m         set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m         \u001b[43mset_skip_guard_eval_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprior_skip_guard_eval_unsafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    843\u001b[39m     _maybe_set_eval_frame(prior)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "fmnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "fmnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(fmnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(fmnist_test, batch_size=128, shuffle=False)\n",
    "\n",
    "sample = fmnist_train[0][0]\n",
    "sample_target = fmnist_train[0][1]\n",
    "print(sample_target)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = dANN([28,28], 1024,254,10, 'local').to(device)\n",
    "print(count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    test_loss, accuracy = test(model, test_loader, device)\n",
    "    print(f'train loss: {train_loss}, test loss: {test_loss}, test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2aecf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "cuda\n",
      "209514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 246/469 [00:08<00:07, 29.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 20\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     test_loss, accuracy \u001b[38;5;241m=\u001b[39m test(model, test_loader, device)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dANN/train.py:9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, device, masked)\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      7\u001b[0m loss_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torchvision/datasets/mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torchvision/transforms/v2/_container.py:51\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     49\u001b[0m needs_unpacking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py:69\u001b[0m, in \u001b[0;36mTransform.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     63\u001b[0m needs_transform_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_transform_list(flat_inputs)\n\u001b[1;32m     64\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_params(\n\u001b[1;32m     65\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     71\u001b[0m ]\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torchvision/transforms/v2/_type_conversion.py:39\u001b[0m, in \u001b[0;36mToImage.transform\u001b[0;34m(self, inpt, params)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m, inpt: Union[torch\u001b[38;5;241m.\u001b[39mTensor, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage, np\u001b[38;5;241m.\u001b[39mndarray], params: Dict[\u001b[38;5;28mstr\u001b[39m, Any]\n\u001b[1;32m     38\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tv_tensors\u001b[38;5;241m.\u001b[39mImage:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_type_conversion.py:16\u001b[0m, in \u001b[0;36mto_image\u001b[0;34m(inpt)\u001b[0m\n\u001b[1;32m     14\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39matleast_3d(inpt))\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inpt, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m---> 16\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mpil_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inpt, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     18\u001b[0m     output \u001b[38;5;241m=\u001b[39m inpt\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torchvision/transforms/functional.py:210\u001b[0m, in \u001b[0;36mpil_to_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    209\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(np\u001b[38;5;241m.\u001b[39marray(pic, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 210\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m    212\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fmnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "fmnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(fmnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(fmnist_test, batch_size=128, shuffle=False)\n",
    "\n",
    "sample = fmnist_train[0][0]\n",
    "sample_target = fmnist_train[0][1]\n",
    "print(sample_target)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = vANN([28,28], 256,32,10).to(device)\n",
    "print(count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device, masked=False)\n",
    "    test_loss, accuracy = test(model, test_loader, device)\n",
    "    print(f'train loss: {train_loss}, test loss: {test_loss}, test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0080fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "cuda\n",
      "104938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:16<00:00, 28.87it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:02<00:00, 30.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.3343751462283673, test loss: 0.773855884618397, test accuracy: 0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:17<00:00, 27.58it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:02<00:00, 32.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6990508116892914, test loss: 0.6794255047659331, test accuracy: 0.7555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:17<00:00, 27.04it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:02<00:00, 30.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6361310403230094, test loss: 0.6370434089551998, test accuracy: 0.7722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:17<00:00, 26.90it/s]\n",
      "Testing:   5%|▌         | 4/79 [00:00<00:02, 25.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     20\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(model, train_loader, optimizer, device)\n\u001b[0;32m---> 21\u001b[0m     test_loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dANN/train.py:33\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTesting\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torchvision/datasets/mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torchvision/transforms/v2/_container.py:52\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m     51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m transform(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fmnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "fmnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(fmnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(fmnist_test, batch_size=128, shuffle=False)\n",
    "\n",
    "sample = fmnist_train[0][0]\n",
    "sample_target = fmnist_train[0][1]\n",
    "print(sample_target)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = dANN([28,28], 128,128 // 4, 10, 'global').to(device)\n",
    "print(count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    test_loss, accuracy = test(model, test_loader, device)\n",
    "    print(f'train loss: {train_loss}, test loss: {test_loss}, test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61665677",
   "metadata": {},
   "source": [
    "### Compare the different models across different parameters counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6c9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m soma_ratio \u001b[38;5;129;01min\u001b[39;00m soma_ratios:\n\u001b[1;32m     19\u001b[0m     g_model \u001b[38;5;241m=\u001b[39m dANN(image_size, parameter_count, \u001b[38;5;28mint\u001b[39m(parameter_count \u001b[38;5;241m*\u001b[39m soma_ratio), \u001b[38;5;241m10\u001b[39m, \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     l_model \u001b[38;5;241m=\u001b[39m \u001b[43mdANN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparameter_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msoma_ratio\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     r_model \u001b[38;5;241m=\u001b[39m dANN(image_size, parameter_count, \u001b[38;5;28mint\u001b[39m(parameter_count \u001b[38;5;241m*\u001b[39m soma_ratio), \u001b[38;5;241m10\u001b[39m, \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m     v_model \u001b[38;5;241m=\u001b[39m vANN(image_size, parameter_count, \u001b[38;5;28mint\u001b[39m(parameter_count \u001b[38;5;241m*\u001b[39m soma_ratio), \u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/dANN/models.py:11\u001b[0m, in \u001b[0;36mdANN.__init__\u001b[0;34m(self, image_size, num_dendrites, num_somas, num_out, type)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdendrites \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(image_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m image_size[\u001b[38;5;241m1\u001b[39m], num_dendrites)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf_mask\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mrf_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_dendrites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_somas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdendrites\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdendrites\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdendrites\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrf_mask\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msomas \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_dendrites, num_somas)\n",
      "File \u001b[0;32m~/dANN/masks.py:22\u001b[0m, in \u001b[0;36mrf_mask\u001b[0;34m(image_size, num_dendrites, num_somas, type, rf_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m         nb \u001b[38;5;241m=\u001b[39m nb_vals(image, center,  (rf_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m+\u001b[39m counter)\n\u001b[1;32m     21\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 22\u001b[0m synapses \u001b[38;5;241m=\u001b[39m \u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m flat_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel_multi_index((synapses[:, \u001b[38;5;241m0\u001b[39m], synapses[:, \u001b[38;5;241m1\u001b[39m]), (image_size[\u001b[38;5;241m0\u001b[39m], image_size[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     24\u001b[0m mask[i, flat_indices] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(dendrite_count, soma_ratio, device, train_loader, test_loader, model_type, rf_type, regularize):\n",
    "    if model_type == 'dendritic':\n",
    "        model = dANN([28,28], dendrite_count, int(dendrite_count * soma_ratio), 10, rf_type)\n",
    "    if model_type == 'vanilla':\n",
    "        model = vANN([28,28], dendrite_count, int(dendrite_count * soma_ratio), 10)\n",
    "    else:\n",
    "        raise NameError('Wrong model type!')\n",
    "    if regularize:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=.001, decoupled_weight_decay=.001)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "    epochs = 20\n",
    "    for i in range(epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, device)\n",
    "        test_loss, accuracy = test(model, test_loader, device)\n",
    "        print(f'train loss: {train_loss}, test loss: {test_loss}, test accuracy: {accuracy}')        \n",
    "\n",
    "\n",
    "\n",
    "fmnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "fmnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(fmnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(fmnist_test, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "paramter_counts = [128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n",
    "soma_ratios = [1/2, 1/4, 1/8]\n",
    "image_size = [28,28]\n",
    "for parameter_count in paramter_counts:\n",
    "    for soma_ratio in soma_ratios:\n",
    "        g_model = dANN(image_size, parameter_count, int(parameter_count * soma_ratio), 10, type = 'global')\n",
    "        l_model = dANN(image_size, parameter_count, int(parameter_count * soma_ratio), 10, type = 'local')\n",
    "        r_model = dANN(image_size, parameter_count, int(parameter_count * soma_ratio), 10, type = 'random')\n",
    "        v_model = vANN(image_size, parameter_count, int(parameter_count * soma_ratio), 10)\n",
    "\n",
    "\n",
    "\n",
    "print(count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "optimizer_reg = torch.optim.Adam(model.parameters(), lr=.001, decoupled_weight_decay=.001)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dfffe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93b804",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6cb1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_matplotlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
