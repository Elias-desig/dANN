{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63259637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from masks import rf_mask, somatic_mask\n",
    "import matplotlib.pyplot as plt\n",
    "img_size = 28\n",
    "d_local_mask = rf_mask([img_size,img_size], img_size**2, type='local', rf_size=16)\n",
    "d_random_mask = rf_mask([img_size,img_size], img_size**2, type='random', rf_size=16)\n",
    "single_rf = d_local_mask[0].view(28,28)\n",
    "s_mask = somatic_mask(200, 100)\n",
    "plt.imshow(single_rf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdc0fb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "single_rf = d_local_mask[25].view(28,28)\n",
    "s_mask = somatic_mask(20, 10)\n",
    "plt.imshow(s_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8357824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "summed = torch.sum(d_local_mask.view(-1, 28, 28), dim=0)\n",
    "summed /= torch.max(summed)\n",
    "plt.imshow(summed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb70dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import dANN, vANN, count_parameters\n",
    "from train import train, test\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "\n",
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # Converts to [0,1] range\n",
    "    v2.Normalize(mean=[0.1307], std=[0.3081])  # MNIST-specific normalization\n",
    "])\n",
    "\n",
    "\n",
    "os.makedirs('./data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843713ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "209514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:34<00:00, 109.95it/s]\n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 151.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.7225063505172729, test loss: 1.6521585905075074, test accuracy: 0.8078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:32<00:00, 114.23it/s]\n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 151.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6507577699661256, test loss: 1.6272512691497802, test accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 458/3750 [00:04<00:29, 112.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 36\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     test_loss, accuracy \u001b[38;5;241m=\u001b[39m test(model, test_loader, device)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dANN/train.py:21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)    \n\u001b[0;32m---> 21\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update the model parameters\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mapply_masks()\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/optim/adam.py:220\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    214\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m            and returns the loss.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/optim/optimizer.py:426\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mis_compiling()\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_built()\n\u001b[0;32m--> 426\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m     ):\n\u001b[1;32m    428\u001b[0m         capturing \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_current_stream_capturing()\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    431\u001b[0m             group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups\n\u001b[1;32m    432\u001b[0m         ):\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/cuda/__init__.py:165\u001b[0m, in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_compiled():\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_nvml_based_avail\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# The user has set an env variable to request this availability check that attempts to avoid fork poisoning by\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# using NVML at the cost of a weaker CUDA availability assessment. Note that if NVML discovery/initialization\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# fails, this assessment falls back to the default CUDA Runtime API assessment (`cudaGetDeviceCount`)\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m device_count() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# The default availability inspection never throws and returns 0 if the driver is missing or can't\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# be initialized. This uses the CUDA Runtime API `cudaGetDeviceCount` which in turn initializes the CUDA Driver\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# API via `cuInit`\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/torch_matplotlib/lib/python3.12/site-packages/torch/cuda/__init__.py:158\u001b[0m, in \u001b[0;36m_nvml_based_avail\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_nvml_based_avail\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPYTORCH_NVML_BASED_CUDA_CHECK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m<frozen os>:783\u001b[0m, in \u001b[0;36mgetenv\u001b[0;34m(key, default)\u001b[0m\n",
      "File \u001b[0;32m<frozen _collections_abc>:807\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, key, default)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:682\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:765\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(value)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=128, shuffle=False)\n",
    "\n",
    "sample = mnist_train[0]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = dANN([28,28], 256,32,10, 'local').to(device)\n",
    "print(count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    test_loss, accuracy = test(model, test_loader, device)\n",
    "    print(f'train loss: {train_loss}, test loss: {test_loss}, test accuracy: {accuracy}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c41dabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "cpu\n",
      "1066740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:02<00:00, 27.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0156344885129664, test loss: 0.5623702093770232, test accuracy: 0.7966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:20<00:00, 22.77it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:02<00:00, 29.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4924597360177843, test loss: 0.4765417685237112, test accuracy: 0.8261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:23<00:00, 19.70it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 23.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.43252164141328603, test loss: 0.44022689929491354, test accuracy: 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.18it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.40251569014622457, test loss: 0.4254935242329972, test accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 16.84it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3826760805682587, test loss: 0.40882786882074573, test accuracy: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.20it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.36787741861617895, test loss: 0.3924261671078356, test accuracy: 0.8562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.30it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.35470034134413386, test loss: 0.3823119833876815, test accuracy: 0.8631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.18it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 23.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3443335847559768, test loss: 0.3736806383615808, test accuracy: 0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:28<00:00, 16.51it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 25.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.33557420826034506, test loss: 0.36625154240976404, test accuracy: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:24<00:00, 19.21it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 22.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.32656634463938566, test loss: 0.3652019417738613, test accuracy: 0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:24<00:00, 19.20it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 20.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3203743046471305, test loss: 0.3546313818874238, test accuracy: 0.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:28<00:00, 16.42it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.3138698885944098, test loss: 0.3509423398896109, test accuracy: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:27<00:00, 17.37it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.30799802016220623, test loss: 0.34510084986686707, test accuracy: 0.8771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 356/469 [00:21<00:06, 16.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m epochs = \u001b[32m20\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     train_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     test_loss, accuracy = test(model, test_loader, device)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dANN-1/train.py:9\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, optimizer, device, masked)\u001b[39m\n\u001b[32m      6\u001b[39m model.train()\n\u001b[32m      7\u001b[39m loss_total = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/datasets/mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = Image.fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/_container.py:51\u001b[39m, in \u001b[36mCompose.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m     49\u001b[39m needs_unpacking = \u001b[38;5;28mlen\u001b[39m(inputs) > \u001b[32m1\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     outputs = \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     inputs = outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py:69\u001b[39m, in \u001b[36mTransform.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m     63\u001b[39m needs_transform_list = \u001b[38;5;28mself\u001b[39m._needs_transform_list(flat_inputs)\n\u001b[32m     64\u001b[39m params = \u001b[38;5;28mself\u001b[39m.make_params(\n\u001b[32m     65\u001b[39m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[32m     66\u001b[39m )\n\u001b[32m     68\u001b[39m flat_outputs = [\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[32m     71\u001b[39m ]\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/_misc.py:304\u001b[39m, in \u001b[36mToDtype.transform\u001b[39m\u001b[34m(self, inpt, params)\u001b[39m\n\u001b[32m    299\u001b[39m         warnings.warn(\n\u001b[32m    300\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mscale was set to True but no dtype was specified for images or videos: no scaling will be done.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    301\u001b[39m         )\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inpt\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/_transform.py:49\u001b[39m, in \u001b[36mTransform._call_kernel\u001b[39m\u001b[34m(self, functional, inpt, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m, functional: Callable, inpt: Any, *args: Any, **kwargs: Any) -> Any:\n\u001b[32m     48\u001b[39m     kernel = _get_kernel(functional, \u001b[38;5;28mtype\u001b[39m(inpt), allow_passthrough=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torchvision/transforms/v2/functional/_utils.py:32\u001b[39m, in \u001b[36m_kernel_tv_tensor_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(inpt, *args, **kwargs)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(kernel)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(inpt, *args, **kwargs):\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# If you're wondering whether we could / should get rid of this wrapper,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# lost after the first operation due to our own __torch_function__\u001b[39;00m\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# logic.\u001b[39;00m\n\u001b[32m     31\u001b[39m     output = kernel(inpt.as_subclass(torch.Tensor), *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtv_tensors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlike\u001b[49m\u001b[43m=\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:841\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m         set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m         \u001b[43mset_skip_guard_eval_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprior_skip_guard_eval_unsafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    843\u001b[39m     _maybe_set_eval_frame(prior)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "fmnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "fmnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(fmnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(fmnist_test, batch_size=128, shuffle=False)\n",
    "\n",
    "sample = fmnist_train[0][0]\n",
    "sample_target = fmnist_train[0][1]\n",
    "print(sample_target)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = dANN([28,28], 1024,254,10, 'local').to(device)\n",
    "print(count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    test_loss, accuracy = test(model, test_loader, device)\n",
    "    print(f'train loss: {train_loss}, test loss: {test_loss}, test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aecf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "cpu\n",
      "209514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:33<00:00, 110.90it/s]\n",
      "Testing: 100%|██████████| 625/625 [00:03<00:00, 157.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.6867819447425505, test loss: 0.6001250242710113, test accuracy: 0.8108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:52<00:00, 71.18it/s]\n",
      "Testing: 100%|██████████| 625/625 [00:06<00:00, 94.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.570402087248365, test loss: 0.5576866467773914, test accuracy: 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:53<00:00, 69.88it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:05<00:00, 111.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5332867049174073, test loss: 0.5551383134335279, test accuracy: 0.8305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:46<00:00, 80.97it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 150.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5314795104071498, test loss: 0.5817412079870701, test accuracy: 0.8321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:45<00:00, 83.10it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 126.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5132690154308337, test loss: 0.563063963471353, test accuracy: 0.8373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:42<00:00, 87.48it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 144.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5248882070761174, test loss: 0.5548522709727287, test accuracy: 0.8442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:47<00:00, 78.45it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:05<00:00, 118.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5115832622138783, test loss: 0.5642714636534453, test accuracy: 0.8493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:40<00:00, 91.76it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 148.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.501454325351119, test loss: 0.6511095854759217, test accuracy: 0.8127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:39<00:00, 94.05it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 153.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5016215972613544, test loss: 0.5748827050894498, test accuracy: 0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:39<00:00, 93.92it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:05<00:00, 118.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4945130720253413, test loss: 0.6706654647640884, test accuracy: 0.8015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:43<00:00, 85.95it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:05<00:00, 120.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.5051805719228436, test loss: 0.6474963768601417, test accuracy: 0.8254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:49<00:00, 75.88it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 130.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4867501896852007, test loss: 0.7250728768311441, test accuracy: 0.8279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:42<00:00, 88.14it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:04<00:00, 148.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4726869915845338, test loss: 0.6900695925414562, test accuracy: 0.8336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:42<00:00, 88.16it/s] \n",
      "Testing: 100%|██████████| 625/625 [00:05<00:00, 117.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4863940643947882, test loss: 0.7320261053316295, test accuracy: 0.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 3400/3750 [00:46<00:04, 72.56it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m epochs = \u001b[32m20\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     train_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     test_loss, accuracy = test(model, test_loader, device)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dANN-1/train.py:9\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, optimizer, device, masked)\u001b[39m\n\u001b[32m      6\u001b[39m model.train()\n\u001b[32m      7\u001b[39m loss_total = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/tqdm/std.py:1191\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1189\u001b[39m dt = cur_t - last_print_t\n\u001b[32m   1190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dt >= mininterval \u001b[38;5;129;01mand\u001b[39;00m cur_t >= min_start_t:\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_print_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1192\u001b[39m     last_print_n = \u001b[38;5;28mself\u001b[39m.last_print_n\n\u001b[32m   1193\u001b[39m     last_print_t = \u001b[38;5;28mself\u001b[39m.last_print_t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/tqdm/std.py:1242\u001b[39m, in \u001b[36mtqdm.update\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_dn(dn)\n\u001b[32m   1241\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_dt(dt)\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlock_args\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlock_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dynamic_miniters:\n\u001b[32m   1244\u001b[39m     \u001b[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[32m   1245\u001b[39m     \u001b[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# at least 5 more iterations.\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maxinterval \u001b[38;5;129;01mand\u001b[39;00m dt >= \u001b[38;5;28mself\u001b[39m.maxinterval:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/tqdm/std.py:1347\u001b[39m, in \u001b[36mtqdm.refresh\u001b[39m\u001b[34m(self, nolock, lock_args)\u001b[39m\n\u001b[32m   1345\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1346\u001b[39m         \u001b[38;5;28mself\u001b[39m._lock.acquire()\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/tqdm/std.py:1495\u001b[39m, in \u001b[36mtqdm.display\u001b[39m\u001b[34m(self, msg, pos)\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;28mself\u001b[39m.moveto(pos)\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[32m   1497\u001b[39m     \u001b[38;5;28mself\u001b[39m.moveto(-pos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/tqdm/std.py:459\u001b[39m, in \u001b[36mtqdm.status_printer.<locals>.print_status\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_status\u001b[39m(s):\n\u001b[32m    458\u001b[39m     len_s = disp_len(s)\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[43mfp_write\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_len\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mlen_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     last_len[\u001b[32m0\u001b[39m] = len_s\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/tqdm/std.py:453\u001b[39m, in \u001b[36mtqdm.status_printer.<locals>.fp_write\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfp_write\u001b[39m(s):\n\u001b[32m    452\u001b[39m     fp.write(\u001b[38;5;28mstr\u001b[39m(s))\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     \u001b[43mfp_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/tqdm/utils.py:196\u001b[39m, in \u001b[36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwargs):\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m e.errno != \u001b[32m5\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/environments/dANN_env2/lib/python3.12/site-packages/ipykernel/iostream.py:609\u001b[39m, in \u001b[36mOutStream.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    607\u001b[39m     \u001b[38;5;28mself\u001b[39m.pub_thread.schedule(evt.set)\n\u001b[32m    608\u001b[39m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    610\u001b[39m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[32m    611\u001b[39m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[32m    612\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIOStream.flush timed out\u001b[39m\u001b[33m\"\u001b[39m, file=sys.__stderr__)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "fmnist_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transforms)\n",
    "fmnist_test = datasets.FashionMNIST(root='./data', train=False, download=True, transform=train_transforms)\n",
    "\n",
    "train_loader = DataLoader(fmnist_train, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(fmnist_test, batch_size=128, shuffle=False)\n",
    "\n",
    "sample = fmnist_train[0][0]\n",
    "sample_target = fmnist_train[0][1]\n",
    "print(sample_target)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = vANN([28,28], 256,32,10).to(device)\n",
    "print(count_parameters(model))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device, masked=False)\n",
    "    test_loss, accuracy = test(model, test_loader, device)\n",
    "    print(f'train loss: {train_loss}, test loss: {test_loss}, test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff29035c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 [[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "   18  19  20  21  22  23  24  25  26  27]\n",
      " [ 28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "   46  47  48  49  50  51  52  53  54  55]\n",
      " [ 56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "   74  75  76  77  78  79  80  81  82  83]\n",
      " [ 84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      "  102 103 104 105 106 107 108 109 110 111]\n",
      " [112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      "  130 131 132 133 134 135 136 137 138 139]\n",
      " [140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n",
      "  158 159 160 161 162 163 164 165 166 167]\n",
      " [168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
      "  186 187 188 189 190 191 192 193 194 195]\n",
      " [196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213\n",
      "  214 215 216 217 218 219 220 221 222 223]\n",
      " [224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241\n",
      "  242 243 244 245 246 247 248 249 250 251]\n",
      " [252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      "  270 271 272 273 274 275 276 277 278 279]\n",
      " [280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297\n",
      "  298 299 300 301 302 303 304 305 306 307]\n",
      " [308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325\n",
      "  326 327 328 329 330 331 332 333 334 335]\n",
      " [336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353\n",
      "  354 355 356 357 358 359 360 361 362 363]\n",
      " [364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      "  382 383 384 385 386 387 388 389 390 391]\n",
      " [392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409\n",
      "  410 411 412 413 414 415 416 417 418 419]\n",
      " [420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437\n",
      "  438 439 440 441 442 443 444 445 446 447]\n",
      " [448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465\n",
      "  466 467 468 469 470 471 472 473 474 475]\n",
      " [476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493\n",
      "  494 495 496 497 498 499 500 501 502 503]\n",
      " [504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      "  522 523 524 525 526 527 528 529 530 531]\n",
      " [532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549\n",
      "  550 551 552 553 554 555 556 557 558 559]\n",
      " [560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577\n",
      "  578 579 580 581 582 583 584 585 586 587]\n",
      " [588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605\n",
      "  606 607 608 609 610 611 612 613 614 615]\n",
      " [616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633\n",
      "  634 635 636 637 638 639 640 641 642 643]\n",
      " [644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661\n",
      "  662 663 664 665 666 667 668 669 670 671]\n",
      " [672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689\n",
      "  690 691 692 693 694 695 696 697 698 699]\n",
      " [700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717\n",
      "  718 719 720 721 722 723 724 725 726 727]\n",
      " [728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745\n",
      "  746 747 748 749 750 751 752 753 754 755]\n",
      " [756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
      "  774 775 776 777 778 779 780 781 782 783]] [[ 5 13]\n",
      " [ 5 14]\n",
      " [ 5 15]\n",
      " [ 5 16]\n",
      " [ 5 17]\n",
      " [ 6 13]\n",
      " [ 6 14]\n",
      " [ 6 15]\n",
      " [ 6 16]\n",
      " [ 6 17]\n",
      " [ 7 13]\n",
      " [ 7 14]\n",
      " [ 7 15]\n",
      " [ 7 16]\n",
      " [ 7 17]\n",
      " [ 8 13]\n",
      " [ 8 14]\n",
      " [ 8 15]\n",
      " [ 8 16]\n",
      " [ 8 17]\n",
      " [ 9 13]\n",
      " [ 9 14]\n",
      " [ 9 15]\n",
      " [ 9 16]\n",
      " [ 9 17]]\n",
      "[210 211 240 268 153 156 265 268 182 183 266 209 182 265 182 209]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGMJJREFUeJzt3X9MVff9x/HXVeBWW7gMES53okPb6lYry5xSYutoJAJLjL+22B9LtGk0OmymrGvD0mrdlrDZpGvaOP1ruiZVW5MqqelcFAt8u4GLVmP8biXC2MTww9aEexErUvl8//Dbu14FLXgvby4+H8lJvOece+/b0xOfvd7D0eOccwIAYJiNsR4AAHB3IkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEgvUAN+rr61Nra6uSk5Pl8XisxwEADJJzTl1dXQoEAhozZuDPOSMuQK2trcrOzrYeAwBwh1paWjRp0qQBt4+4ACUnJ0uSHtUPlaBE42kAAIP1hXr1kT4I/3k+kJgFaNu2bXr11VfV3t6u3Nxcvfnmm5o7d+5tn/flX7slKFEJHgIEAHHn/+8weruvUWJyEcI777yjsrIybd68WR9//LFyc3NVVFSkCxcuxOLtAABxKCYBeu2117R69Wo988wz+s53vqMdO3Zo/Pjx+uMf/xiLtwMAxKGoB+jq1as6ceKECgsL//smY8aosLBQdXV1N+3f09OjUCgUsQAARr+oB+izzz7TtWvXlJmZGbE+MzNT7e3tN+1fUVEhn88XXrgCDgDuDuY/iFpeXq5gMBheWlparEcCAAyDqF8Fl56errFjx6qjoyNifUdHh/x+/037e71eeb3eaI8BABjhov4JKCkpSbNnz1ZVVVV4XV9fn6qqqpSfnx/ttwMAxKmY/BxQWVmZVq5cqe9///uaO3euXn/9dXV3d+uZZ56JxdsBAOJQTAK0YsUKffrpp9q0aZPa29v13e9+V4cOHbrpwgQAwN3L45xz1kN8VSgUks/nU4EWcycEAIhDX7heVatSwWBQKSkpA+5nfhUcAODuRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhIsB4AiHeB+uRBP6e27qEYTHKz+fn/O6TnDWW++zfWD+m9cPfiExAAwAQBAgCYiHqAXnnlFXk8nohlxowZ0X4bAECci8l3QA899JCOHDny3zdJ4KsmAECkmJQhISFBfr8/Fi8NABglYvId0NmzZxUIBDR16lQ9/fTTOnfu3ID79vT0KBQKRSwAgNEv6gHKy8vTrl27dOjQIW3fvl3Nzc167LHH1NXV1e/+FRUV8vl84SU7OzvaIwEARqCoB6ikpEQ//vGPNWvWLBUVFemDDz5QZ2en3n333X73Ly8vVzAYDC8tLS3RHgkAMALF/OqA1NRUPfjgg2psbOx3u9frldfrjfUYAIARJuY/B3Tp0iU1NTUpKysr1m8FAIgjUQ/Q888/r5qaGv373//W3/72Ny1dulRjx47Vk08+Ge23AgDEsaj/Fdz58+f15JNP6uLFi5o4caIeffRR1dfXa+LEidF+KwBAHIt6gPbu3RvtlwRGtKHcuHOoNwkdrOG66SkwFNwLDgBgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEfN/kA4Y7YbrxqI7J//PoJ8zjZuRYgTjExAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDds4A7VDtMdp4dyZ+uh3ql7uH5PuLvxCQgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSIE7NNQbfg4WNwjFaMMnIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjBe5Q6yNdw/I+96t+0M9pHcb3AgaLT0AAABMECABgYtABqq2t1aJFixQIBOTxeHTgwIGI7c45bdq0SVlZWRo3bpwKCwt19uzZaM0LABglBh2g7u5u5ebmatu2bf1u37p1q9544w3t2LFDx44d07333quioiJduXLljocFAIweg74IoaSkRCUlJf1uc87p9ddf10svvaTFixdLkt566y1lZmbqwIEDeuKJJ+5sWgDAqBHV74Cam5vV3t6uwsLC8Dqfz6e8vDzV1dX1+5yenh6FQqGIBQAw+kU1QO3t7ZKkzMzMiPWZmZnhbTeqqKiQz+cLL9nZ2dEcCQAwQplfBVdeXq5gMBheWlparEcCAAyDqAbI7/dLkjo6OiLWd3R0hLfdyOv1KiUlJWIBAIx+UQ1QTk6O/H6/qqqqwutCoZCOHTum/Pz8aL4VACDODfoquEuXLqmxsTH8uLm5WadOnVJaWpomT56sDRs26De/+Y0eeOAB5eTk6OWXX1YgENCSJUuiOTcAIM4NOkDHjx/X448/Hn5cVlYmSVq5cqV27dqlF154Qd3d3VqzZo06Ozv16KOP6tChQ7rnnnuiNzUAIO55nHPOeoivCoVC8vl8KtBiJXgSrccBAAzSF65X1apUMBi85ff65lfBAQDuTgQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMSgA1RbW6tFixYpEAjI4/HowIEDEdtXrVolj8cTsRQXF0drXgDAKDHoAHV3dys3N1fbtm0bcJ/i4mK1tbWFlz179tzRkACA0SdhsE8oKSlRSUnJLffxer3y+/1DHgoAMPrF5Dug6upqZWRkaPr06Vq3bp0uXrw44L49PT0KhUIRCwBg9It6gIqLi/XWW2+pqqpKv/vd71RTU6OSkhJdu3at3/0rKirk8/nCS3Z2drRHAgCMQB7nnBvykz0e7d+/X0uWLBlwn3/961+aNm2ajhw5ogULFty0vaenRz09PeHHoVBI2dnZKtBiJXgShzoaAMDIF65X1apUMBhUSkrKgPvF/DLsqVOnKj09XY2Njf1u93q9SklJiVgAAKNfzAN0/vx5Xbx4UVlZWbF+KwBAHBn0VXCXLl2K+DTT3NysU6dOKS0tTWlpadqyZYuWL18uv9+vpqYmvfDCC7r//vtVVFQU1cEBAPFt0AE6fvy4Hn/88fDjsrIySdLKlSu1fft2nT59Wn/605/U2dmpQCCghQsX6te//rW8Xm/0pgYAxL1BB6igoEC3um7hL3/5yx0NBAC4O3AvOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGJQAaqoqNCcOXOUnJysjIwMLVmyRA0NDRH7XLlyRaWlpZowYYLuu+8+LV++XB0dHVEdGgAQ/wYVoJqaGpWWlqq+vl6HDx9Wb2+vFi5cqO7u7vA+Gzdu1Pvvv699+/appqZGra2tWrZsWdQHBwDEN49zzg31yZ9++qkyMjJUU1Oj+fPnKxgMauLEidq9e7d+9KMfSZI++eQTffvb31ZdXZ0eeeSR275mKBSSz+dTgRYrwZM41NEAAEa+cL2qVqWCwaBSUlIG3O+OvgMKBoOSpLS0NEnSiRMn1Nvbq8LCwvA+M2bM0OTJk1VXV9fva/T09CgUCkUsAIDRb8gB6uvr04YNGzRv3jzNnDlTktTe3q6kpCSlpqZG7JuZman29vZ+X6eiokI+ny+8ZGdnD3UkAEAcGXKASktLdebMGe3du/eOBigvL1cwGAwvLS0td/R6AID4kDCUJ61fv14HDx5UbW2tJk2aFF7v9/t19epVdXZ2RnwK6ujokN/v7/e1vF6vvF7vUMYAAMSxQX0Ccs5p/fr12r9/v44ePaqcnJyI7bNnz1ZiYqKqqqrC6xoaGnTu3Dnl5+dHZ2IAwKgwqE9ApaWl2r17tyorK5WcnBz+Xsfn82ncuHHy+Xx69tlnVVZWprS0NKWkpOi5555Tfn7+17oCDgBw9xhUgLZv3y5JKigoiFi/c+dOrVq1SpL0+9//XmPGjNHy5cvV09OjoqIi/eEPf4jKsACA0eOOfg4oFvg5IACIb8Pyc0AAAAwVAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMagAVVRUaM6cOUpOTlZGRoaWLFmihoaGiH0KCgrk8XgilrVr10Z1aABA/BtUgGpqalRaWqr6+nodPnxYvb29Wrhwobq7uyP2W716tdra2sLL1q1bozo0ACD+JQxm50OHDkU83rVrlzIyMnTixAnNnz8/vH78+PHy+/3RmRAAMCrd0XdAwWBQkpSWlhax/u2331Z6erpmzpyp8vJyXb58ecDX6OnpUSgUilgAAKPfoD4BfVVfX582bNigefPmaebMmeH1Tz31lKZMmaJAIKDTp0/rxRdfVENDg957771+X6eiokJbtmwZ6hgAgDjlcc65oTxx3bp1+vOf/6yPPvpIkyZNGnC/o0ePasGCBWpsbNS0adNu2t7T06Oenp7w41AopOzsbBVosRI8iUMZDQBg6AvXq2pVKhgMKiUlZcD9hvQJaP369Tp48KBqa2tvGR9JysvLk6QBA+T1euX1eocyBgAgjg0qQM45Pffcc9q/f7+qq6uVk5Nz2+ecOnVKkpSVlTWkAQEAo9OgAlRaWqrdu3ersrJSycnJam9vlyT5fD6NGzdOTU1N2r17t374wx9qwoQJOn36tDZu3Kj58+dr1qxZMfkNAADi06C+A/J4PP2u37lzp1atWqWWlhb95Cc/0ZkzZ9Td3a3s7GwtXbpUL7300i3/HvCrQqGQfD4f3wEBQJyKyXdAt2tVdna2ampqBvOSAIC7FPeCAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYSLAe4EbOOUnSF+qVnPEwAIBB+0K9kv775/lARlyAurq6JEkf6QPjSQAAd6Krq0s+n2/A7R53u0QNs76+PrW2tio5OVkejydiWygUUnZ2tlpaWpSSkmI0oT2Ow3Uch+s4DtdxHK4bCcfBOaeuri4FAgGNGTPwNz0j7hPQmDFjNGnSpFvuk5KSclefYF/iOFzHcbiO43Adx+E66+Nwq08+X+IiBACACQIEADARVwHyer3avHmzvF6v9SimOA7XcRyu4zhcx3G4Lp6Ow4i7CAEAcHeIq09AAIDRgwABAEwQIACACQIEADARNwHatm2bvvWtb+mee+5RXl6e/v73v1uPNOxeeeUVeTyeiGXGjBnWY8VcbW2tFi1apEAgII/HowMHDkRsd85p06ZNysrK0rhx41RYWKizZ8/aDBtDtzsOq1atuun8KC4uthk2RioqKjRnzhwlJycrIyNDS5YsUUNDQ8Q+V65cUWlpqSZMmKD77rtPy5cvV0dHh9HEsfF1jkNBQcFN58PatWuNJu5fXATonXfeUVlZmTZv3qyPP/5Yubm5Kioq0oULF6xHG3YPPfSQ2trawstHH31kPVLMdXd3Kzc3V9u2bet3+9atW/XGG29ox44dOnbsmO69914VFRXpypUrwzxpbN3uOEhScXFxxPmxZ8+eYZww9mpqalRaWqr6+nodPnxYvb29Wrhwobq7u8P7bNy4Ue+//7727dunmpoatba2atmyZYZTR9/XOQ6StHr16ojzYevWrUYTD8DFgblz57rS0tLw42vXrrlAIOAqKioMpxp+mzdvdrm5udZjmJLk9u/fH37c19fn/H6/e/XVV8PrOjs7ndfrdXv27DGYcHjceBycc27lypVu8eLFJvNYuXDhgpPkampqnHPX/9snJia6ffv2hff55z//6SS5uro6qzFj7sbj4JxzP/jBD9zPfvYzu6G+hhH/Cejq1as6ceKECgsLw+vGjBmjwsJC1dXVGU5m4+zZswoEApo6daqefvppnTt3znokU83NzWpvb484P3w+n/Ly8u7K86O6uloZGRmaPn261q1bp4sXL1qPFFPBYFCSlJaWJkk6ceKEent7I86HGTNmaPLkyaP6fLjxOHzp7bffVnp6umbOnKny8nJdvnzZYrwBjbibkd7os88+07Vr15SZmRmxPjMzU5988onRVDby8vK0a9cuTZ8+XW1tbdqyZYsee+wxnTlzRsnJydbjmWhvb5ekfs+PL7fdLYqLi7Vs2TLl5OSoqalJv/zlL1VSUqK6ujqNHTvWeryo6+vr04YNGzRv3jzNnDlT0vXzISkpSampqRH7jubzob/jIElPPfWUpkyZokAgoNOnT+vFF19UQ0OD3nvvPcNpI434AOG/SkpKwr+eNWuW8vLyNGXKFL377rt69tlnDSfDSPDEE0+Ef/3www9r1qxZmjZtmqqrq7VgwQLDyWKjtLRUZ86cuSu+B72VgY7DmjVrwr9++OGHlZWVpQULFqipqUnTpk0b7jH7NeL/Ci49PV1jx4696SqWjo4O+f1+o6lGhtTUVD344INqbGy0HsXMl+cA58fNpk6dqvT09FF5fqxfv14HDx7Uhx9+GPHPt/j9fl29elWdnZ0R+4/W82Gg49CfvLw8SRpR58OID1BSUpJmz56tqqqq8Lq+vj5VVVUpPz/fcDJ7ly5dUlNTk7KysqxHMZOTkyO/3x9xfoRCIR07duyuPz/Onz+vixcvjqrzwzmn9evXa//+/Tp69KhycnIits+ePVuJiYkR50NDQ4POnTs3qs6H2x2H/pw6dUqSRtb5YH0VxNexd+9e5/V63a5du9w//vEPt2bNGpeamura29utRxtWP//5z111dbVrbm52f/3rX11hYaFLT093Fy5csB4tprq6utzJkyfdyZMnnST32muvuZMnT7r//Oc/zjnnfvvb37rU1FRXWVnpTp8+7RYvXuxycnLc559/bjx5dN3qOHR1dbnnn3/e1dXVuebmZnfkyBH3ve99zz3wwAPuypUr1qNHzbp165zP53PV1dWura0tvFy+fDm8z9q1a93kyZPd0aNH3fHjx11+fr7Lz883nDr6bnccGhsb3a9+9St3/Phx19zc7CorK93UqVPd/PnzjSePFBcBcs65N998002ePNklJSW5uXPnuvr6euuRht2KFStcVlaWS0pKct/85jfdihUrXGNjo/VYMffhhx86STctK1eudM5dvxT75ZdfdpmZmc7r9boFCxa4hoYG26Fj4FbH4fLly27hwoVu4sSJLjEx0U2ZMsWtXr161P1PWn+/f0lu586d4X0+//xz99Of/tR94xvfcOPHj3dLly51bW1tdkPHwO2Ow7lz59z8+fNdWlqa83q97v7773e/+MUvXDAYtB38BvxzDAAAEyP+OyAAwOhEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJj4P3xwIEtLuLK6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage as scn\n",
    "import torch\n",
    "\n",
    "\n",
    "def nb_vals(matrix, index, size):\n",
    "\n",
    "    coords = np.unravel_index(index, matrix.shape)\n",
    "    arr_shape = matrix.shape\n",
    "    dist = np.ones(arr_shape)\n",
    "    dist[coords] = 0\n",
    "    dist = scn.distance_transform_cdt(dist, metric='chessboard')\n",
    "    \n",
    "    nb_indices = np.transpose(np.nonzero(dist <= size))\n",
    "    return nb_indices\n",
    "\n",
    "seed = 1\n",
    "rng = np.random.default_rng(seed)\n",
    "image_size = [28, 28]\n",
    "layer_size = image_size[0]*image_size[1]\n",
    "image =  np.arange(layer_size).reshape((image_size[0], image_size[1]))\n",
    "center = 211\n",
    "nb = nb_vals(image, center, 2)\n",
    "\n",
    "synapses = rng.choice(nb, 16)\n",
    "print(center,image, nb)\n",
    "vis = np.zeros(image_size)\n",
    "for coord in nb:\n",
    "    vis[coord[0], coord[1]] = 0.5\n",
    "for coord in synapses:\n",
    "    vis[coord[0], coord[1]] = 0.75\n",
    "\n",
    "\n",
    "ravelled = np.ravel_multi_index((synapses[:, 0], synapses[:, 1]), (28, 28))\n",
    "print(ravelled)\n",
    "vis[np.unravel_index(center, image.shape)] = 1.0\n",
    "plt.imshow(vis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0080fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dANN_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
